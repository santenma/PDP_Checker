import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from collections import Counter
import re
from urllib.parse import urlparse, quote_plus
import time
import nltk
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import warnings
import json
import random
from datetime import datetime

# Importar wordcloud de forma opcional
try:
    from wordcloud import WordCloud
    WORDCLOUD_AVAILABLE = True
except ImportError:
    WORDCLOUD_AVAILABLE = False

# Suprimir advertencias
warnings.filterwarnings('ignore')

# ConfiguraciÃ³n inicial de la pÃ¡gina
st.set_page_config(
    page_title="AnÃ¡lisis Competitivo de Productos",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Descargar recursos de NLTK si es necesario
@st.cache_resource
def download_nltk_data():
    """Descarga datos de NLTK necesarios"""
    try:
        nltk.data.find('tokenizers/punkt')
    except LookupError:
        try:
            nltk.download('punkt', quiet=True)
        except Exception:
            pass

    try:
        nltk.data.find('corpora/stopwords')
    except LookupError:
        try:
            nltk.download('stopwords', quiet=True)
        except Exception:
            pass

download_nltk_data()

def main():
    # CSS personalizado mejorado
    st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        background: linear-gradient(90deg, #FF6B6B 0%, #4ECDC4 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 2rem;
    }
    .success-message {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 0.5rem;
        padding: 1rem 1.5rem;
        margin-bottom: 1rem;
        color: #155724;
    }
    .warning-message {
        background-color: #fff3cd;
        border: 1px solid #ffeeba;
        border-radius: 0.5rem;
        padding: 1rem 1.5rem;
        margin-bottom: 1rem;
        color: #856404;
    }
    .gap-card {
        background: #f8f9fa;
        border-left: 4px solid #FF6B6B;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 0.25rem;
    }
    .feature-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Header principal
    st.markdown('<h1 class="main-header">ğŸ¯ AnÃ¡lisis Competitivo de Productos</h1>', unsafe_allow_html=True)
    st.markdown("### Analiza productos de la competencia y encuentra oportunidades de mejora")
    
    # Mensaje de estado de librerÃ­as
    if not WORDCLOUD_AVAILABLE:
        st.info("â„¹ï¸ WordCloud no estÃ¡ disponible. Las nubes de palabras se mostrarÃ¡n como grÃ¡ficos de barras.")
    
    # InformaciÃ³n de ayuda mejorada
    with st.expander("ğŸ“š Â¿CÃ³mo usar esta herramienta?"):
        st.markdown("""
        ### ğŸ¯ Flujo de Trabajo Recomendado
        
        1. **ğŸ”— URL de Referencia**: Ingresa la URL de TU producto
        2. **ğŸ” URLs de Competencia**: AÃ±ade URLs de productos competidores
        3. **ğŸ“Š AnÃ¡lisis AutomÃ¡tico**: La herramienta extraerÃ¡ y compararÃ¡:
           - TÃ­tulos y descripciones
           - CaracterÃ­sticas y especificaciones
           - Filtros y categorÃ­as
           - Precios y posicionamiento
        4. **ğŸ¯ AnÃ¡lisis de GAPS**: Identifica quÃ© le falta a tu producto
        5. **ğŸ’¡ Insights**: ObtÃ©n recomendaciones basadas en datos
        
        ### âœ… Sitios Compatibles
        - **Amazon** â­ Mejor compatibilidad
        - **eBay** â­ Muy buena compatibilidad
        - **AliExpress** âœ… Generalmente funciona
        - **Tiendas pequeÃ±as** âœ… Menos restricciones
        
        ### ğŸš« Sitios con Restricciones
        - MediaMarkt, PCComponentes, El Corte InglÃ©s
        - Grandes retailers con protecciÃ³n anti-bot
        
        ### ğŸ’¡ Tips Pro
        - Usa el **modo agresivo** para sitios difÃ­ciles
        - Aumenta el **delay** entre requests para evitar bloqueos
        - Analiza productos similares, no idÃ©nticos
        - Combina con Google Shopping para vista de mercado
        """)
    
    # Sidebar mejorado
    st.sidebar.header("âš™ï¸ ConfiguraciÃ³n")
    
    # Opciones de anÃ¡lisis
    st.sidebar.subheader("ğŸ“‹ Tipos de AnÃ¡lisis")
    analyze_terms = st.sidebar.checkbox("ğŸ”¤ TÃ©rminos clave", value=True)
    analyze_filters = st.sidebar.checkbox("ğŸ›ï¸ Filtros y categorÃ­as", value=True)
    analyze_features = st.sidebar.checkbox("â­ CaracterÃ­sticas", value=True)
    analyze_gaps = st.sidebar.checkbox("ğŸ¯ AnÃ¡lisis de GAPS", value=True)
    analyze_pricing = st.sidebar.checkbox("ğŸ’° AnÃ¡lisis de precios", value=True)
    
    if WORDCLOUD_AVAILABLE:
        show_wordcloud = st.sidebar.checkbox("â˜ï¸ Nube de palabras", value=True)
    else:
        show_wordcloud = False
    
    st.sidebar.markdown("---")
    
    # ConfiguraciÃ³n avanzada
    st.sidebar.subheader("ğŸ”§ ConfiguraciÃ³n Avanzada")
    
    top_n = st.sidebar.slider("ğŸ“Š Top N resultados", 5, 50, 20)
    delay = st.sidebar.slider("â±ï¸ Delay entre requests (seg)", 0.5, 5.0, 2.0, 0.5)
    
    st.sidebar.markdown("**ğŸ›¡ï¸ Anti-detecciÃ³n:**")
    retry_403 = st.sidebar.checkbox("ğŸ”„ Reintentar bloqueados", value=True)
    aggressive_mode = st.sidebar.checkbox("ğŸš€ Modo agresivo", value=False)
    rotate_headers = st.sidebar.checkbox("ğŸ”„ Rotar User-Agents", value=False)
    
    if aggressive_mode:
        delay = max(delay, 3.0)
    
    # PestaÃ±as principales
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š AnÃ¡lisis de URLs", "ğŸ›’ Google Shopping", "ğŸ“ˆ ComparaciÃ³n"])
    
    with tab1:
        st.header("ğŸ”— AnÃ¡lisis de Productos por URL")
        
        # URL de referencia (nuevo)
        st.subheader("ğŸ¯ Producto de Referencia (Tu Producto)")
        reference_url = st.text_input(
            "URL de tu producto (opcional - para anÃ¡lisis de gaps):",
            placeholder="https://tu-tienda.com/tu-producto",
            help="Esta serÃ¡ la referencia para comparar con la competencia"
        )
        
        # URLs de competencia
        st.subheader("ğŸ” Productos de la Competencia")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            urls_input = st.text_area(
                "URLs de productos competidores (una por lÃ­nea):",
                height=200,
                placeholder="""https://www.amazon.es/dp/B08N5WRWNW
https://www.ebay.es/itm/123456789
https://www.aliexpress.com/item/1005001234567890.html""",
                help="Ingresa las URLs de productos que quieres analizar"
            )
        
        with col2:
            st.markdown("**âœ… Compatibles:**")
            st.success("amazon.es/com")
            st.success("ebay.es/com")
            st.success("aliexpress.com")
            st.markdown("**âš ï¸ DifÃ­ciles:**")
            st.warning("mediamarkt.es")
            st.warning("pccomponentes.com")
        
        # ValidaciÃ³n de URLs
        if urls_input.strip() or reference_url.strip():
            all_urls = []
            
            if reference_url.strip() and reference_url.startswith(('http://', 'https://')):
                all_urls.append(('reference', reference_url.strip()))
            
            if urls_input.strip():
                comp_urls = [url.strip() for url in urls_input.split('\n') if url.strip()]
                for url in comp_urls:
                    if url.startswith(('http://', 'https://')):
                        all_urls.append(('competitor', url))
            
            if all_urls:
                st.success(f"âœ… {len(all_urls)} URLs vÃ¡lidas detectadas")
        
        # BotÃ³n de anÃ¡lisis
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            analyze_button = st.button(
                "ğŸš€ INICIAR ANÃLISIS", 
                type="primary", 
                use_container_width=True,
                disabled=not (urls_input.strip() or reference_url.strip())
            )
        
        if analyze_button:
            analyzer = ProductBenchmarkAnalyzer()
            
            # Progreso
            st.markdown("### ğŸ”„ Procesando URLs...")
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # MÃ©tricas
            col1, col2, col3 = st.columns(3)
            with col1:
                success_metric = st.metric("âœ… Exitosos", 0)
            with col2:
                failed_metric = st.metric("âŒ Fallidos", 0)
            with col3:
                total_metric = st.metric("ğŸ“Š Total", len(all_urls))
            
            reference_data = None
            competitor_data = []
            failed_count = 0
            success_count = 0
            
            # Procesar cada URL
            for i, (url_type, url) in enumerate(all_urls):
                status_text.markdown(f'ğŸ” **Procesando {url_type} {i+1}/{len(all_urls)}**  \n`{url[:70]}...`')
                
                if i > 0:
                    time.sleep(delay * 1.5 if aggressive_mode else delay)
                
                data = analyzer.extract_content_from_url(url, rotate_headers)
                
                if data:
                    if url_type == 'reference':
                        reference_data = data
                    else:
                        competitor_data.append(data)
                    success_count += 1
                    success_metric.metric("âœ… Exitosos", success_count)
                else:
                    failed_count += 1
                    failed_metric.metric("âŒ Fallidos", failed_count)
                    
                    # Retry si estÃ¡ habilitado
                    if retry_403:
                        status_text.markdown(f'ğŸ”„ **Reintentando...**')
                        time.sleep(5)
                        retry_data = analyzer.extract_content_from_url(url, True)
                        if retry_data:
                            if url_type == 'reference':
                                reference_data = retry_data
                            else:
                                competitor_data.append(retry_data)
                            success_count += 1
                            failed_count -= 1
                            success_metric.metric("âœ… Exitosos", success_count)
                            failed_metric.metric("âŒ Fallidos", failed_count)
                
                progress_bar.progress((i + 1) / len(all_urls))
            
            status_text.markdown('âœ… **AnÃ¡lisis completado**')
            
            # Guardar datos en session state
            st.session_state['reference_data'] = reference_data
            st.session_state['competitor_data'] = competitor_data
            st.session_state['all_data'] = [reference_data] if reference_data else [] + competitor_data
            
            if not st.session_state['all_data']:
                st.error("âŒ No se pudo extraer informaciÃ³n de ninguna URL.")
                return
            
            # Mensaje de Ã©xito
            st.markdown(f"""
            <div class="success-message">
                <strong>ğŸ‰ Â¡AnÃ¡lisis completado!</strong><br>
                Se procesaron <strong>{success_count}</strong> de <strong>{len(all_urls)}</strong> productos
            </div>
            """, unsafe_allow_html=True)
            
            # PestaÃ±as de resultados
            result_tabs = st.tabs([
                "ğŸ“Š Resumen", 
                "ğŸ¯ AnÃ¡lisis de GAPS",
                "ğŸ”¤ TÃ©rminos", 
                "ğŸ›ï¸ Filtros", 
                "â­ CaracterÃ­sticas",
                "ğŸ’° Precios",
                "ğŸ“ˆ Visualizaciones",
                "ğŸ’¾ Exportar"
            ])
            
            with result_tabs[0]:  # Resumen
                st.header("ğŸ“Š Resumen del AnÃ¡lisis")
                
                # MÃ©tricas principales
                col1, col2, col3, col4 = st.columns(4)
                
                all_data = st.session_state['all_data']
                
                with col1:
                    st.metric("ğŸ”— Productos Analizados", len(all_data))
                
                with col2:
                    total_features = sum(len(data.get('features', [])) for data in all_data)
                    st.metric("â­ Total CaracterÃ­sticas", total_features)
                
                with col3:
                    total_specs = sum(len(data.get('specifications', {})) for data in all_data)
                    st.metric("ğŸ”§ Total Especificaciones", total_specs)
                
                with col4:
                    products_with_price = sum(1 for data in all_data if data.get('price'))
                    st.metric("ğŸ’° Con Precio", products_with_price)
                
                # Tabla resumen
                summary_data = []
                for i, data in enumerate(all_data):
                    is_reference = (i == 0 and reference_data)
                    summary_data.append({
                        'Tipo': 'ğŸ¯ Referencia' if is_reference else f'ğŸ” Competidor {i}',
                        'Dominio': data.get('domain', 'N/A'),
                        'TÃ­tulo': data.get('title', 'Sin tÃ­tulo')[:60] + '...',
                        'Precio': data.get('price', 'N/A'),
                        'CaracterÃ­sticas': len(data.get('features', [])),
                        'Especificaciones': len(data.get('specifications', {})),
                        'Filtros': len(data.get('filters', []))
                    })
                
                df_summary = pd.DataFrame(summary_data)
                st.dataframe(df_summary, use_container_width=True, hide_index=True)
            
            with result_tabs[1]:  # AnÃ¡lisis de GAPS
                st.header("ğŸ¯ AnÃ¡lisis de GAPS")
                
                if reference_data and competitor_data:
                    gaps = analyzer.analyze_gaps(reference_data, competitor_data)
                    
                    # CaracterÃ­sticas Ãºnicas de la competencia
                    if gaps['unique_competitor_features']:
                        st.subheader("âš¡ CaracterÃ­sticas que tiene la competencia")
                        st.markdown('<div class="warning-message">', unsafe_allow_html=True)
                        st.markdown("**Oportunidades de mejora detectadas:**")
                        for feature in gaps['unique_competitor_features'][:10]:
                            st.markdown(f"â€¢ {feature}")
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Especificaciones faltantes
                    if gaps['missing_specs']:
                        st.subheader("ğŸ“‹ Especificaciones faltantes")
                        cols = st.columns(3)
                        for i, spec in enumerate(gaps['missing_specs'][:12]):
                            cols[i % 3].warning(f"ğŸ“Œ {spec}")
                    
                    # Filtros que usa la competencia
                    if gaps['missing_filters']:
                        st.subheader("ğŸ›ï¸ Filtros adicionales en competencia")
                        st.info("Considera aÃ±adir estos filtros a tu tienda:")
                        filter_df = pd.DataFrame(
                            {'Filtro': gaps['missing_filters'][:20]},
                            index=range(1, min(21, len(gaps['missing_filters'])+1))
                        )
                        st.dataframe(filter_df, use_container_width=True)
                    
                    # AnÃ¡lisis de precio
                    if gaps['price_difference']:
                        st.subheader("ğŸ’° AnÃ¡lisis de Precio")
                        price_data = gaps['price_difference']
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Tu Precio", f"{price_data['reference']:.2f}â‚¬")
                        with col2:
                            st.metric("Promedio Competencia", f"{price_data['competitors_avg']:.2f}â‚¬")
                        with col3:
                            diff_color = "ğŸŸ¢" if price_data['difference'] < 0 else "ğŸ”´"
                            st.metric(
                                "Diferencia",
                                f"{abs(price_data['difference']):.2f}â‚¬",
                                f"{diff_color} {abs(price_data['percentage']):.1f}%"
                            )
                        
                        if price_data['percentage'] > 20:
                            st.warning("âš ï¸ Tu precio es significativamente mayor que la competencia")
                        elif price_data['percentage'] < -20:
                            st.info("ğŸ’¡ Tu precio es muy competitivo, podrÃ­as considerar ajustarlo")
                
                else:
                    st.info("ğŸ’¡ AÃ±ade una URL de referencia y URLs de competencia para ver el anÃ¡lisis de gaps")
            
            # Resto de pestaÃ±as con anÃ¡lisis tradicionales...
            with result_tabs[2]:  # TÃ©rminos
                if analyze_terms:
                    st.header("ğŸ”¤ TÃ©rminos MÃ¡s Relevantes")
                    terms = analyzer.analyze_terms(all_data)
                    top_terms = terms.most_common(top_n)
                    
                    if top_terms:
                        df_terms = pd.DataFrame(top_terms, columns=['TÃ©rmino', 'Frecuencia'])
                        
                        fig = px.bar(
                            df_terms, 
                            x='Frecuencia', 
                            y='TÃ©rmino',
                            orientation='h',
                            color='Frecuencia',
                            color_continuous_scale='viridis',
                            title="TÃ©rminos clave mÃ¡s frecuentes"
                        )
                        fig.update_layout(height=600, yaxis={'categoryorder':'total ascending'})
                        st.plotly_chart(fig, use_container_width=True)
            
            with result_tabs[7]:  # Exportar
                st.header("ğŸ’¾ Exportar Resultados")
                
                # Preparar datos para exportaciÃ³n
                export_data = []
                
                for i, data in enumerate(all_data):
                    is_reference = (i == 0 and reference_data)
                    export_data.append({
                        'Tipo': 'Referencia' if is_reference else 'Competidor',
                        'URL': data.get('url', ''),
                        'Dominio': data.get('domain', ''),
                        'TÃ­tulo': data.get('title', ''),
                        'DescripciÃ³n': data.get('description', '')[:500],
                        'Precio': data.get('price', ''),
                        'CaracterÃ­sticas': ' | '.join(data.get('features', [])),
                        'Especificaciones': json.dumps(data.get('specifications', {}), ensure_ascii=False),
                        'Filtros': ' | '.join(data.get('filters', [])),
                        'CategorÃ­as': ' | '.join(data.get('categories', [])),
                        'Fecha_ExtracciÃ³n': data.get('extracted_at', '')
                    })
                
                df_export = pd.DataFrame(export_data)
                
                # BotÃ³n de descarga
                csv = df_export.to_csv(index=False, encoding='utf-8')
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.download_button(
                        label="ğŸ“¥ Descargar AnÃ¡lisis Completo (CSV)",
                        data=csv,
                        file_name=f"analisis_competitivo_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
                
                with col2:
                    # Exportar solo gaps si existe
                    if reference_data and competitor_data:
                        gaps = analyzer.analyze_gaps(reference_data, competitor_data)
                        gaps_text = f"""ANÃLISIS DE GAPS - {datetime.now().strftime('%Y-%m-%d %H:%M')}
                        
CARACTERÃSTICAS ÃšNICAS DE COMPETENCIA:
{chr(10).join('â€¢ ' + f for f in gaps['unique_competitor_features'][:20])}

ESPECIFICACIONES FALTANTES:
{chr(10).join('â€¢ ' + s for s in gaps['missing_specs'][:20])}

FILTROS ADICIONALES EN COMPETENCIA:
{chr(10).join('â€¢ ' + f for f in gaps['missing_filters'][:20])}

ANÃLISIS DE PRECIO:
{json.dumps(gaps['price_difference'], indent=2) if gaps['price_difference'] else 'No disponible'}
"""
                        st.download_button(
                            label="ğŸ“¥ Descargar AnÃ¡lisis de GAPS (TXT)",
                            data=gaps_text,
                            file_name=f"gaps_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                            mime="text/plain",
                            use_container_width=True
                        )
    
    with tab2:  # Google Shopping
        st.header("ğŸ›’ AnÃ¡lisis con Google Shopping")
        st.info("ğŸ’¡ Analiza el mercado completo sin restricciones de sitios web")
        
        search_query = st.text_input(
            "Â¿QuÃ© producto quieres analizar?",
            placeholder="Ejemplo: auriculares bluetooth deportivos",
            help="Describe el producto para buscar en el mercado"
        )
        
        num_results = st.slider("NÃºmero de resultados", 5, 30, 15)
        
        if st.button("ğŸ” Buscar en Google Shopping", type="primary", disabled=not search_query):
            shopping_analyzer = GoogleShoppingAnalyzer()
            
            with st.spinner("Buscando productos..."):
                products = shopping_analyzer.search_products_free(search_query, num_results)
            
            if products:
                st.success(f"âœ… Se encontraron {len(products)} productos")
                
                analysis = shopping_analyzer.analyze_shopping_data(products)
                
                # Sub-pestaÃ±as para resultados
                shop_tabs = st.tabs(["ğŸ“‹ Productos", "ğŸ“Š Tiendas", "ğŸ’° Precios", "ğŸ”¤ TÃ©rminos"])
                
                with shop_tabs[0]:
                    st.subheader("Productos Encontrados")
                    for i, product in enumerate(products[:10], 1):
                        col1, col2, col3 = st.columns([3, 1, 1])
                        with col1:
                            st.markdown(f"**{i}. {product.get('title', 'Sin tÃ­tulo')[:80]}**")
                        with col2:
                            st.markdown(f"ğŸ’° **{product.get('price', 'N/A')}**")
                        with col3:
                            st.markdown(f"ğŸª {product.get('source', 'N/A')}")
                        st.divider()
                
                with shop_tabs[1]:
                    if analysis['sources']:
                        sources_df = pd.DataFrame(
                            list(analysis['sources'].items()), 
                            columns=['Tienda', 'Productos']
                        ).sort_values('Productos', ascending=False)
                        
                        fig = px.bar(
                            sources_df, 
                            x='Productos', 
                            y='Tienda',
                            orientation='h',
                            title="DistribuciÃ³n por Tienda"
                        )
                        st.plotly_chart(fig, use_container_width=True)
                
                with shop_tabs[2]:
                    if analysis.get('price_ranges'):
                        price_info = analysis['price_ranges']
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("ğŸ’µ MÃ­nimo", f"{price_info['min']:.2f}â‚¬")
                        with col2:
                            st.metric("ğŸ’¸ MÃ¡ximo", f"{price_info['max']:.2f}â‚¬")
                        with col3:
                            st.metric("ğŸ“Š Promedio", f"{price_info['avg']:.2f}â‚¬")
                        with col4:
                            st.metric("ğŸ”¢ Con Precio", price_info['count'])
                
                with shop_tabs[3]:
                    if analysis['common_terms']:
                        terms_data = analysis['common_terms'].most_common(25)
                        terms_df = pd.DataFrame(terms_data, columns=['TÃ©rmino', 'Frecuencia'])
                        
                        fig = px.bar(
                            terms_df.head(15),
                            x='Frecuencia',
                            y='TÃ©rmino',
                            orientation='h',
                            title="TÃ©rminos mÃ¡s frecuentes",
                            color='Frecuencia',
                            color_continuous_scale='plasma'
                        )
                        fig.update_layout(height=500, yaxis={'categoryorder':'total ascending'})
                        st.plotly_chart(fig, use_container_width=True)
            else:
                st.error("No se encontraron productos. Intenta con otro tÃ©rmino.")
    
    with tab3:  # ComparaciÃ³n
        st.header("ğŸ“ˆ ComparaciÃ³n Visual")
        
        if 'all_data' in st.session_state and st.session_state['all_data']:
            all_data = st.session_state['all_data']
            
            # Crear comparaciÃ³n visual
            st.subheader("ğŸ” Matriz de ComparaciÃ³n")
            
            comparison_matrix = []
            for data in all_data:
                comparison_matrix.append({
                    'Producto': data.get('title', 'Sin tÃ­tulo')[:50],
                    'Precio': 1 if data.get('price') else 0,
                    'DescripciÃ³n': len(data.get('description', '')) > 100,
                    'CaracterÃ­sticas': len(data.get('features', [])),
                    'Especificaciones': len(data.get('specifications', {})),
                    'ImÃ¡genes': len(data.get('images', [])),
                    'CategorÃ­as': len(data.get('categories', []))
                })
            
            df_comparison = pd.DataFrame(comparison_matrix)
            
            # Heatmap de caracterÃ­sticas
            fig = px.imshow(
                df_comparison.set_index('Producto').T,
                labels=dict(x="Productos", y="Atributos", color="Valor"),
                aspect="auto",
                color_continuous_scale="RdYlGn",
                title="Mapa de Calor - Completitud de InformaciÃ³n"
            )
            # Ajustar el Ã¡ngulo de las etiquetas del eje x
            fig.update_xaxes(tickangle=45)
            st.plotly_chart(fig, use_container_width=True)
            
            # GrÃ¡fico de radar para comparaciÃ³n
            if len(all_data) <= 5:  # Solo mostrar radar si hay 5 o menos productos
                st.subheader("ğŸ¯ ComparaciÃ³n Radar")
                
                categories = ['CaracterÃ­sticas', 'Especificaciones', 'ImÃ¡genes', 'CategorÃ­as', 'Filtros']
                
                fig = go.Figure()
                
                for i, data in enumerate(all_data):
                    values = [
                        len(data.get('features', [])),
                        len(data.get('specifications', {})),
                        len(data.get('images', [])),
                        len(data.get('categories', [])),
                        len(data.get('filters', []))
                    ]
                    
                    fig.add_trace(go.Scatterpolar(
                        r=values,
                        theta=categories,
                        fill='toself',
                        name=f"Producto {i+1}"
                    ))
                
                fig.update_layout(
                    polar=dict(
                        radialaxis=dict(
                            visible=True,
                            range=[0, max([
                                max(len(d.get('features', [])), 
                                    len(d.get('specifications', {})),
                                    len(d.get('images', [])),
                                    len(d.get('categories', [])),
                                    len(d.get('filters', [])))
                                for d in all_data
                            ])]
                        )
                    ),
                    showlegend=True,
                    title="ComparaciÃ³n de Completitud por Producto"
                )
                
                st.plotly_chart(fig, use_container_width=True)
            
            # Insights automÃ¡ticos
            st.subheader("ğŸ’¡ Insights AutomÃ¡ticos")
            
            insights = []
            
            # AnÃ¡lisis de completitud
            completeness_scores = []
            for data in all_data:
                score = 0
                score += 1 if data.get('title') else 0
                score += 1 if data.get('description') else 0
                score += 1 if data.get('price') else 0
                score += min(len(data.get('features', [])) / 5, 1)
                score += min(len(data.get('specifications', {})) / 5, 1)
                score += min(len(data.get('images', [])) / 3, 1)
                completeness_scores.append(score / 6 * 100)
            
            best_product_idx = completeness_scores.index(max(completeness_scores))
            worst_product_idx = completeness_scores.index(min(completeness_scores))
            
            insights.append(f"ğŸ“Š **Producto mÃ¡s completo**: Producto {best_product_idx + 1} ({completeness_scores[best_product_idx]:.1f}% completitud)")
            insights.append(f"âš ï¸ **Producto menos completo**: Producto {worst_product_idx + 1} ({completeness_scores[worst_product_idx]:.1f}% completitud)")
            
            # AnÃ¡lisis de precios
            prices = []
            for data in all_data:
                if data.get('price'):
                    price_match = re.search(r'[\d,]+\.?\d*', data.get('price', '').replace(',', ''))
                    if price_match:
                        try:
                            prices.append(float(price_match.group()))
                        except:
                            pass
            
            if prices:
                avg_price = sum(prices) / len(prices)
                insights.append(f"ğŸ’° **Precio promedio**: {avg_price:.2f}â‚¬")
                insights.append(f"ğŸ’µ **Rango de precios**: {min(prices):.2f}â‚¬ - {max(prices):.2f}â‚¬")
            
            # Mostrar insights
            for insight in insights:
                st.info(insight)
            
            # Recomendaciones
            st.subheader("ğŸ¯ Recomendaciones")
            
            recommendations = []
            
            if 'reference_data' in st.session_state and st.session_state['reference_data']:
                ref_data = st.session_state['reference_data']
                ref_score = completeness_scores[0]
                
                if ref_score < 70:
                    recommendations.append("ğŸ”´ **Urgente**: Tu producto tiene poca informaciÃ³n. AÃ±ade mÃ¡s descripciones y caracterÃ­sticas.")
                elif ref_score < 85:
                    recommendations.append("ğŸŸ¡ **Importante**: Tu producto estÃ¡ bien pero puede mejorar. Considera aÃ±adir mÃ¡s especificaciones tÃ©cnicas.")
                else:
                    recommendations.append("ğŸŸ¢ **Excelente**: Tu producto tiene informaciÃ³n muy completa.")
                
                if not ref_data.get('price'):
                    recommendations.append("ğŸ’° **Precio**: Considera mostrar el precio claramente en la pÃ¡gina del producto.")
                
                if len(ref_data.get('images', [])) < 3:
                    recommendations.append("ğŸ“¸ **ImÃ¡genes**: AÃ±ade mÃ¡s imÃ¡genes del producto (mÃ­nimo 3-5).")
            
            if not recommendations:
                recommendations.append("ğŸ’¡ AÃ±ade una URL de referencia para obtener recomendaciones personalizadas.")
            
            for rec in recommendations:
                st.markdown(rec)
        
        else:
            st.info("ğŸ‘† Primero realiza un anÃ¡lisis en la pestaÃ±a 'AnÃ¡lisis de URLs' para ver comparaciones.")
    
    # Footer con informaciÃ³n adicional
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666; padding: 2rem;'>
        <p>ğŸ¯ <strong>AnÃ¡lisis Competitivo de Productos</strong> v2.0</p>
        <p>Desarrollado para ayudarte a mejorar tu estrategia de producto</p>
        <p>ğŸ’¡ Tip: Analiza regularmente a tu competencia para mantenerte actualizado</p>
    </div>
    """, unsafe_allow_html=True)

class GoogleShoppingAnalyzer:
    """Obtiene resultados bÃ¡sicos de Google Shopping y realiza un anÃ¡lisis simple."""

    def __init__(self):
        # Cabeceras aleatorias para evitar bloqueos sencillos
        self.headers_options = [
            {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept-Language': 'es-ES,es;q=0.9,en;q=0.8'
            },
            {
                'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept-Language': 'es,en-US;q=0.7,en;q=0.3'
            }
        ]

    def _get_headers(self):
        """Devuelve cabeceras aleatorias."""
        return random.choice(self.headers_options)

    def search_products_free(self, query, num_results=10):
        """Busca productos en Google Shopping sin necesidad de API.

        Parameters
        ----------
        query: str
            TÃ©rmino de bÃºsqueda.
        num_results: int
            NÃºmero aproximado de resultados a recuperar.
        """
        url = f"https://www.google.com/search?tbm=shop&q={quote_plus(query)}&num={num_results}"
        products = []
        try:
            resp = requests.get(url, headers=self._get_headers(), timeout=10)
            soup = BeautifulSoup(resp.text, "html.parser")

            for item in soup.select("div.sh-dgr__content"):
                title_el = item.select_one("h3")
                price_el = item.select_one("span.a8Pemb")
                source_el = item.select_one("div.aULzUe span")

                products.append({
                    "title": title_el.get_text(strip=True) if title_el else "",
                    "price": price_el.get_text(strip=True) if price_el else "",
                    "source": source_el.get_text(strip=True) if source_el else ""
                })

                if len(products) >= num_results:
                    break
        except Exception:
            # En caso de fallo, devolver lista vacÃ­a para evitar errores en la app
            return []

        return products

    def analyze_shopping_data(self, products):
        """Realiza un anÃ¡lisis simple de los productos obtenidos."""
        if not products:
            return {}

        # Conteo de tiendas
        store_counts = Counter(p.get("source", "Desconocido") for p in products)

        # ConversiÃ³n de precios a valores numÃ©ricos
        prices = []
        for p in products:
            price = p.get("price")
            if price:
                value = re.sub(r"[^0-9.,]", "", price).replace(",", ".")
                try:
                    prices.append(float(value))
                except Exception:
                    pass

        # TÃ©rminos mÃ¡s frecuentes de los tÃ­tulos
        terms = Counter()
        for p in products:
            terms.update(re.findall(r"\w+", p.get("title", "").lower()))

        return {
            "stores": dict(store_counts),
            "price_stats": {
                "min": min(prices) if prices else None,
                "max": max(prices) if prices else None,
                "avg": sum(prices) / len(prices) if prices else None,
            },
            "terms": dict(terms.most_common(20)),
        }

class ProductBenchmarkAnalyzer:
    def __init__(self):
        """Inicializa el analizador con stopwords mejoradas"""
        try:
            # Stopwords bÃ¡sicas en espaÃ±ol e inglÃ©s
            spanish_stopwords = set([
                'el', 'la', 'de', 'que', 'y', 'a', 'en', 'un', 'es', 'se', 'no', 'te', 'lo', 
                'le', 'da', 'su', 'por', 'son', 'con', 'para', 'al', 'del', 'las', 'una', 
                'su', 'me', 'si', 'tu', 'mÃ¡s', 'muy', 'pero', 'como', 'son', 'los', 'este',
                'esta', 'esto', 'ese', 'esa', 'esos', 'esas', 'tiene', 'ser', 'hacer',
                'estar', 'todo', 'todos', 'toda', 'todas', 'cuando', 'donde', 'como',
                'porque', 'aunque', 'desde', 'hasta', 'entre', 'sobre', 'bajo', 'sin'
            ])
            
            english_stopwords = set([
                'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 
                'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 
                'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 
                'might', 'must', 'can', 'this', 'that', 'these', 'those', 'all', 'any', 
                'some', 'each', 'every', 'both', 'either', 'neither', 'one', 'two', 'three'
            ])
            
            # Palabras relacionadas con e-commerce que NO queremos analizar
            ecommerce_stopwords = set([
                'aÃ±adir', 'carrito', 'comprar', 'compra', 'pedido', 'envio', 'envÃ­o', 
                'entrega', 'prevista', 'generado', 'stock', 'disponible', 'agotado',
                'precio', 'oferta', 'descuento', 'rebaja', 'promocion', 'promociÃ³n',
                'gratis', 'gratuito', 'iva', 'incluido', 'excluido', 'gastos',
                'valoracion', 'valoraciÃ³n', 'opinion', 'opiniÃ³n', 'comentario',
                'puntuacion', 'puntuaciÃ³n', 'estrella', 'estrellas', 'valorar',
                'recomendar', 'recomiendo', 'cliente', 'clientes', 'usuario', 'usuarios',
                'cada', 'solo', 'sÃ³lo', 'solamente', 'Ãºnicamente', 'tambiÃ©n', 'ademÃ¡s',
                'producto', 'productos', 'articulo', 'artÃ­culo', 'item', 'items',
                'marca', 'modelo', 'referencia', 'codigo', 'cÃ³digo', 'sku',
                'categoria', 'categorÃ­a', 'seccion', 'secciÃ³n', 'departamento',
                'buscar', 'busqueda', 'bÃºsqueda', 'filtrar', 'filtro', 'filtros',
                'ordenar', 'clasificar', 'mostrar', 'ver', 'todos', 'todas',
                'inicio', 'home', 'tienda', 'shop', 'store', 'online',
                'web', 'website', 'pagina', 'pÃ¡gina', 'sitio', 'portal',
                'cookies', 'politica', 'polÃ­tica', 'privacidad', 'terminos', 'tÃ©rminos',
                'condiciones', 'legal', 'aviso', 'contacto', 'ayuda', 'soporte'
            ])
            
            try:
                nltk_spanish = set(nltk.corpus.stopwords.words('spanish'))
                nltk_english = set(nltk.corpus.stopwords.words('english'))
                self.stop_words = spanish_stopwords | english_stopwords | ecommerce_stopwords | nltk_spanish | nltk_english
            except:
                self.stop_words = spanish_stopwords | english_stopwords | ecommerce_stopwords
                
        except:
            # Fallback mÃ­nimo
            self.stop_words = set(['el', 'la', 'de', 'que', 'y', 'a', 'en', 'the', 'and', 'or', 'aÃ±adir', 'carrito', 'entrega', 'envio'])
        
        self.results = []
        self.headers_options = [
            {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
                'Accept-Language': 'es-ES,es;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1'
            },
            {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'es-es',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive'
            },
            {
                'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'es,en-US;q=0.7,en;q=0.3',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive'
            }
        ]
        
    def extract_content_from_url(self, url, rotate_headers=False):
        """Extrae contenido relevante de una URL de producto"""
        try:
            # Seleccionar headers
            if rotate_headers:
                headers = random.choice(self.headers_options)
            else:
                headers = self.headers_options[0]
            
            # Usar session para mantener cookies
            session = requests.Session()
            session.headers.update(headers)
            
            response = session.get(url, timeout=20, allow_redirects=True)
            
            # Si obtenemos 403, intentamos estrategias adicionales
            if response.status_code == 403:
                # Estrategia 1: Headers mÃ­nimos
                minimal_headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0'
                }
                session.headers.clear()
                session.headers.update(minimal_headers)
                time.sleep(3)
                response = session.get(url, timeout=20, allow_redirects=True)
                
                # Estrategia 2: Si sigue fallando, probar con otro user-agent
                if response.status_code == 403:
                    session.headers.update({
                        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1'
                    })
                    time.sleep(5)
                    response = session.get(url, timeout=20, allow_redirects=True)
            
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Extraer informaciÃ³n del producto
            product_data = {
                'url': url,
                'domain': urlparse(url).netloc,
                'title': self._extract_title(soup),
                'description': self._extract_description(soup),
                'features': self._extract_features(soup),
                'specifications': self._extract_specifications(soup),
                'price': self._extract_price(soup),
                'filters': self._extract_filters(soup),
                'categories': self._extract_categories(soup),
                'images': self._extract_images(soup),
                'extracted_at': datetime.now().isoformat()
            }
            
            return product_data
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 403:
                domain = urlparse(url).netloc
                st.warning(f"ğŸš« Acceso denegado a {domain}")
                self._suggest_alternatives(domain)
            else:
                st.warning(f"âš ï¸ Error HTTP {e.response.status_code} con {url[:50]}...")
            return None
        except requests.exceptions.RequestException as e:
            st.warning(f"âš ï¸ Error de conexiÃ³n con {url[:50]}...: {str(e)}")
            return None
        except Exception as e:
            st.warning(f"âš ï¸ Error procesando {url[:50]}...: {str(e)}")
            return None
    
    def _suggest_alternatives(self, domain):
        """Sugiere alternativas para sitios bloqueados"""
        alternatives = {
            'mediamarkt': "ğŸ’¡ **Alternativa para MediaMarkt:** Busca el mismo producto en Amazon o eBay",
            'pccomponentes': "ğŸ’¡ **Alternativa para PCComponentes:** Prueba con Amazon o tiendas especializadas",
            'elcorteingles': "ğŸ’¡ **Alternativa para El Corte InglÃ©s:** Busca en Amazon o tiendas del fabricante"
        }
        
        for site, message in alternatives.items():
            if site in domain.lower():
                st.info(message)
                break
    
    def _extract_title(self, soup):
        """Extrae el tÃ­tulo del producto"""
        selectors = [
            'h1[class*="title"]',
            'h1[class*="product"]',
            '[data-testid*="title"]',
            '[class*="product-title"]',
            '[class*="product-name"]',
            '[id*="title"]',
            'h1',
            'title'
        ]
        
        for selector in selectors:
            elements = soup.select(selector)
            for element in elements:
                text = element.get_text().strip()
                if text and len(text) > 5 and len(text) < 300:
                    return text
        return ""
    
    def _extract_description(self, soup):
        """Extrae la descripciÃ³n del producto enfocÃ¡ndose en contenido relevante"""
        description = ""
        
        # Selectores especÃ­ficos para descripciones de producto
        description_selectors = [
            '[class*="product-description"]',
            '[class*="description"]',
            '[class*="summary"]',
            '[class*="overview"]',
            '[class*="details"]',
            '[data-testid*="description"]',
            '[class*="product-info"]',
            '[class*="caracteristicas"]',
            'meta[name="description"]'
        ]
        
        # Elementos a excluir
        excluded_classes = [
            'nav', 'menu', 'header', 'footer', 'sidebar', 'cart', 'carrito',
            'checkout', 'payment', 'shipping', 'delivery', 'price', 'precio',
            'review', 'opinion', 'rating', 'valoracion', 'breadcrumb'
        ]
        
        for selector in description_selectors:
            if 'meta' in selector:
                element = soup.select_one(selector)
                if element:
                    desc = element.get('content', '')
                    if desc and len(desc) > 30:
                        description += desc + " "
            else:
                elements = soup.select(selector)
                for element in elements:
                    # Verificar que no sea un elemento excluido
                    element_class = element.get('class', [])
                    element_id = element.get('id', '')
                    
                    is_excluded = any(
                        excluded in str(element_class).lower() or 
                        excluded in element_id.lower() 
                        for excluded in excluded_classes
                    )
                    
                    if not is_excluded:
                        text = element.get_text().strip()
                        if text and len(text) > 30 and len(text) < 3000:
                            if not self._is_ecommerce_text(text):
                                description += text + " "
        
        return description.strip()
    
    def _is_ecommerce_text(self, text):
        """Detecta si un texto es relacionado con e-commerce y no con producto"""
        text_lower = text.lower()
        
        # Patrones que indican texto de e-commerce
        ecommerce_patterns = [
            'aÃ±adir al carrito', 'comprar ahora', 'envÃ­o gratis',
            'opiniones de', 'valoraciones de', 'polÃ­tica de',
            'mi cuenta', 'iniciar sesiÃ³n', 'comparar producto',
            'stock disponible', 'descuento del', 'gastos de envÃ­o'
        ]
        
        pattern_count = sum(1 for pattern in ecommerce_patterns if pattern in text_lower)
        
        # Si mÃ¡s del 30% del texto son palabras de e-commerce, lo descartamos
        words = text_lower.split()
        ecommerce_word_count = sum(1 for word in words if word in self.stop_words)
        ecommerce_ratio = ecommerce_word_count / len(words) if words else 0
        
        return pattern_count > 2 or ecommerce_ratio > 0.3
    
    def _extract_features(self, soup):
        """Extrae caracterÃ­sticas y features del producto"""
        features = []
        
        # Buscar listas de caracterÃ­sticas
        feature_selectors = [
            '[class*="feature"] li',
            '[class*="benefit"] li',
            '[class*="highlight"] li',
            '[class*="spec"] li',
            'ul[class*="feature"] li',
            '.features li',
            '.benefits li',
            'div[class*="feature"]'
        ]
        
        for selector in feature_selectors:
            elements = soup.select(selector)
            for element in elements:
                text = element.get_text().strip()
                if (text and 
                    len(text) > 10 and 
                    len(text) < 500 and 
                    not re.match(r'^\d+$', text) and
                    not text.lower().startswith(('http', 'www', 'mailto'))):
                    features.append(text)
        
        # Eliminar duplicados manteniendo orden
        seen = set()
        unique_features = []
        for feature in features:
            if feature.lower() not in seen:
                seen.add(feature.lower())
                unique_features.append(feature)
        
        return unique_features[:50]
    
    def _extract_specifications(self, soup):
        """Extrae especificaciones tÃ©cnicas"""
        specs = {}
        
        # Buscar tablas de especificaciones
        spec_selectors = [
            'table[class*="spec"]',
            'table[class*="detail"]',
            'table[class*="tech"]',
            'dl[class*="spec"]',
            'table'
        ]
        
        for selector in spec_selectors:
            elements = soup.select(selector)
            for element in elements:
                if element.name == 'table':
                    rows = element.find_all('tr')
                    for row in rows:
                        cells = row.find_all(['td', 'th'])
                        if len(cells) >= 2:
                            key = cells[0].get_text().strip()
                            value = cells[1].get_text().strip()
                            if key and value and len(key) < 100 and len(value) < 200:
                                specs[key] = value
                elif element.name == 'dl':
                    dts = element.find_all('dt')
                    dds = element.find_all('dd')
                    for dt, dd in zip(dts, dds):
                        key = dt.get_text().strip()
                        value = dd.get_text().strip()
                        if key and value:
                            specs[key] = value
        
        return specs
    
    def _extract_price(self, soup):
        """Extrae informaciÃ³n de precio"""
        price_selectors = [
            '[class*="price"]',
            '[class*="cost"]',
            '[class*="amount"]',
            '[data-testid*="price"]',
            '[id*="price"]',
            'span[itemprop="price"]',
            'meta[itemprop="price"]'
        ]
        
        for selector in price_selectors:
            elements = soup.select(selector)
            for element in elements:
                if element.name == 'meta':
                    price = element.get('content', '')
                    if price:
                        return price
                else:
                    text = element.get_text().strip()
                    # Buscar patrones de precio
                    price_patterns = [
                        r'[â‚¬$Â£Â¥]\s*[\d,]+\.?\d*',
                        r'[\d,]+\.?\d*\s*[â‚¬$Â£Â¥]',
                        r'[\d,]+\.?\d*\s*EUR?'
                    ]
                    
                    for pattern in price_patterns:
                        price_match = re.search(pattern, text, re.IGNORECASE)
                        if price_match:
                            return price_match.group().strip()
        
        return ""
    
    def _extract_filters(self, soup):
        """Extrae filtros disponibles en la pÃ¡gina"""
        filters = []
        
        filter_selectors = [
            '[class*="filter"] a',
            '[class*="facet"] a',
            'select option',
            '[type="checkbox"] + label',
            '[class*="refinement"]'
        ]
        
        for selector in filter_selectors:
            elements = soup.select(selector)
            for element in elements:
                text = element.get_text().strip()
                if (text and 
                    len(text) > 2 and 
                    len(text) < 80 and
                    not text.lower().startswith(('http', 'www')) and
                    not re.match(r'^\d+$', text)):
                    filters.append(text)
        
        return list(set(filters))[:100]
    
    def _extract_categories(self, soup):
        """Extrae categorÃ­as del producto"""
        categories = []
        
        category_selectors = [
            '[class*="breadcrumb"] a',
            '[class*="category"] a',
            '.breadcrumb a',
            'nav[aria-label*="breadcrumb"] a'
        ]
        
        for selector in category_selectors:
            elements = soup.select(selector)
            for element in elements:
                text = element.get_text().strip()
                if (text and 
                    text.lower() not in ['home', 'inicio', 'tienda'] and
                    len(text) > 2 and 
                    len(text) < 50):
                    categories.append(text)
        
        return categories
    
    def _extract_images(self, soup):
        """Extrae URLs de imÃ¡genes del producto"""
        images = []
        
        image_selectors = [
            'img[class*="product"]',
            'img[data-testid*="product"]',
            '[class*="gallery"] img',
            '[class*="image"] img',
            'picture img'
        ]
        
        for selector in image_selectors:
            elements = soup.select(selector)
            for element in elements:
                src = element.get('src') or element.get('data-src')
                if src and not any(x in src.lower() for x in ['placeholder', 'loading', 'spinner']):
                    images.append(src)
        
        return list(set(images))[:10]
    
    def analyze_terms(self, all_data):
        """Analiza los tÃ©rminos mÃ¡s frecuentes enfocÃ¡ndose en caracterÃ­sticas de producto"""
        all_text = ""
        
        for data in all_data:
            # Priorizar tÃ­tulo y caracterÃ­sticas
            title_text = data.get('title', '')
            features_text = " ".join(data.get('features', []))
            specs_keys = " ".join(data.get('specifications', {}).keys())
            specs_values = " ".join(data.get('specifications', {}).values())
            
            # Dar mÃ¡s peso a caracterÃ­sticas tÃ©cnicas
            all_text += f" {title_text} {features_text} {features_text} {specs_keys} {specs_values} "
            
            # Agregar descripciÃ³n filtrada
            description = data.get('description', '')
            if description:
                sentences = description.split('.')
                for sentence in sentences:
                    if self._is_product_relevant_sentence(sentence):
                        all_text += sentence + " "
        
        # Limpiar y tokenizar texto
        words = re.findall(r'\b[a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]{3,}\b', all_text.lower())
        
        # Filtrar palabras relevantes
        filtered_words = []
        for word in words:
            if (word not in self.stop_words and 
                len(word) >= 3 and 
                not word.isdigit() and
                self._is_product_term(word)):
                filtered_words.append(word)
        
        return Counter(filtered_words)
    
    def _is_product_relevant_sentence(self, sentence):
        """Determina si una oraciÃ³n es relevante para el producto"""
        sentence_lower = sentence.lower().strip()
        
        # Frases que indican caracterÃ­sticas tÃ©cnicas
        positive_indicators = [
            'caracterÃ­sticas', 'especificaciones', 'incluye', 'cuenta con',
            'tecnologÃ­a', 'material', 'diseÃ±o', 'tamaÃ±o', 'dimensiones',
            'memoria', 'procesador', 'pantalla', 'baterÃ­a', 'compatible'
        ]
        
        # Frases no relevantes
        negative_indicators = [
            'aÃ±adir', 'carrito', 'comprar', 'precio', 'envÃ­o',
            'opiniÃ³n', 'valoraciÃ³n', 'stock', 'oferta', 'cliente'
        ]
        
        positive_score = sum(1 for indicator in positive_indicators if indicator in sentence_lower)
        negative_score = sum(1 for indicator in negative_indicators if indicator in sentence_lower)
        
        return positive_score > negative_score and len(sentence.strip()) > 20
    
    def _is_product_term(self, word):
        """Determina si una palabra es relevante para describir productos"""
        irrelevant_terms = {
            'pÃ¡gina', 'sitio', 'web', 'usuario', 'cliente', 'cuenta',
            'compra', 'pedido', 'pago', 'envÃ­o', 'precio', 'oferta',
            'opiniÃ³n', 'valoraciÃ³n', 'comentario', 'estrella'
        }
        
        return word not in irrelevant_terms
    
    def analyze_filters(self, all_data):
        """Analiza los filtros mÃ¡s comunes"""
        all_filters = []
        
        for data in all_data:
            all_filters.extend(data.get('filters', []))
        
        return Counter(all_filters)
    
    def analyze_features(self, all_data):
        """Analiza las caracterÃ­sticas mÃ¡s mencionadas"""
        all_features = []
        
        for data in all_data:
            all_features.extend(data.get('features', []))
        
        # Extraer palabras clave de las caracterÃ­sticas
        feature_words = []
        for feature in all_features:
            words = re.findall(r'\b[a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]{3,}\b', feature.lower())
            words = [word for word in words if word not in self.stop_words]
            feature_words.extend(words)
        
        return Counter(feature_words)
    
    def analyze_gaps(self, reference_data, comparison_data):
        """Analiza gaps entre producto de referencia y competencia"""
        gaps = {
            'missing_features': [],
            'missing_specs': [],
            'missing_filters': [],
            'unique_competitor_features': [],
            'price_difference': None,
            'category_differences': []
        }
        
        if not reference_data or not comparison_data:
            return gaps
        
        # Analizar caracterÃ­sticas faltantes
        ref_features = set([f.lower() for f in reference_data.get('features', [])])
        
        for comp_data in comparison_data:
            comp_features = set([f.lower() for f in comp_data.get('features', [])])
            
            # CaracterÃ­sticas que tiene la competencia pero no la referencia
            unique_comp = comp_features - ref_features
            gaps['unique_competitor_features'].extend(list(unique_comp))
            
            # CaracterÃ­sticas que tiene la referencia pero no la competencia
            missing = ref_features - comp_features
            gaps['missing_features'].extend(list(missing))
        
        # Analizar especificaciones faltantes
        ref_specs = set(reference_data.get('specifications', {}).keys())
        
        for comp_data in comparison_data:
            comp_specs = set(comp_data.get('specifications', {}).keys())
            missing_specs = ref_specs - comp_specs
            gaps['missing_specs'].extend(list(missing_specs))
        
        # Analizar filtros
        ref_filters = set(reference_data.get('filters', []))
        all_comp_filters = set()
        
        for comp_data in comparison_data:
            all_comp_filters.update(comp_data.get('filters', []))
        
        gaps['missing_filters'] = list(all_comp_filters - ref_filters)
        
        # Analizar diferencias de precio
        ref_price = self._extract_price_value(reference_data.get('price', ''))
        if ref_price:
            comp_prices = []
            for comp_data in comparison_data:
                comp_price = self._extract_price_value(comp_data.get('price', ''))
                if comp_price:
                    comp_prices.append(comp_price)
            
            if comp_prices:
                avg_comp_price = sum(comp_prices) / len(comp_prices)
                gaps['price_difference'] = {
                    'reference': ref_price,
                    'competitors_avg': avg_comp_price,
                    'difference': ref_price - avg_comp_price,
                    'percentage': ((ref_price - avg_comp_price) / avg_comp_price) * 100
                }
        
        # Eliminar duplicados
        gaps['missing_features'] = list(set(gaps['missing_features']))
        gaps['missing_specs'] = list(set(gaps['missing_specs']))
        gaps['unique_competitor_features'] = list(set(gaps['unique_competitor_features']))
        
        return gaps
    
    def _extract_price_value(self, price_text):
        """Extrae el valor numÃ©rico del precio"""
        if not price_text:
            return None
        
        # Buscar nÃºmeros en el texto del precio
        price_match = re.search(r'[\d,]+\.?\d*', price_text.replace(',', ''))
        if price_match:
            try:
                return float(price_match.group())
            except:
                return None
        return None


if __name__ == "__main__":
    main()
